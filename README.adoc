= NMP Kafka Workshop Exercises

:bootstrap-host: 7.tcp.eu.ngrok.io
:bootstrap-port: 16233
:bootstrap-server: {bootstrap-host}:{bootstrap-port}
:ui-url: https://69a1-80-91-33-141.eu.ngrok.io
:schema-registry: http://1358-80-91-33-141.eu.ngrok.io

== Part 1

Go to Confluent's https://developer.confluent.io/get-started/[Getting Started] guide.

* You may select any of the listed programming languages.

* In the *Kafka Setup* section, set *Kafka Location* to "Other".
** Bootstrap Server URL: `{bootstrap-server}`

[TIP]
====
Run the following command to verify that you are able to connect to the Kafka Cluster:
[source,bash,subs="+attributes"]
----
nc -vz {bootstrap-host} {bootstrap-port}
----
====

* Go to this {ui-url}[Kafka UI] to create a topic.
** Set *Number of partitions* to 3.
** Since everyone is connecting to the same cluster, you can make up your own unique topic name to avoid colliding with others.

* Follow the rest of the *Getting Started* guide to produce and consume your own events.
** Remember to substitute with your own topic name where applicable.

[TIP]
====
You can check your topic's partitions, messages and consumers in the UI.
====

* Try running two consumers at the same time, and then produce some messages. How are the messages distributed among the consumers?

== Part 2

Consume the topic `"public.nmp-kafka-workshop.announcements"`.
This topic contains data encoded using https://avro.apache.org/[Apache Avro], with the following schema:

[source,json]
----
{
  "namespace": "examples.avro",
  "type": "record",
  "name": "Announcement",
  "fields": [
    {
      "name": "author",
      "type": "string"
    },
    {
      "name": "message",
      "type": "string"
    }
  ]
}
----

Use the following Schema Registry URL: `pass:a[{schema-registry}]`

Solving this task will require you to do some digging on your own.

* https://github.com/confluentinc/examples/tree/7.3.1-post/clients/cloud/java/src/main/java/io/confluent/examples/clients/cloud[Java examples]
* https://github.com/confluentinc/confluent-kafka-python/tree/master/examples[Python examples]
* https://github.com/confluentinc/confluent-kafka-go/tree/master/examples[Go examples]
* https://github.com/confluentinc/confluent-kafka-dotnet/tree/master/examples[.NET examples]

For some languages you have the choice between deserializing into a _generic_ record (i.e. a hash map or dictionary) or a _specific_ record (i.e. a data type generated from the schema).

Some pre-generated data types for the `Announcement` record are available in this repository.
